{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "20_linguistic_features.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kullawattana/thesis_2020_spacy_colab/blob/master/20_linguistic_features.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BcnBdk7hHXDn",
        "outputId": "1d0e9708-228b-4c46-ebdd-20f87e7b5c2b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import spacy\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "doc = nlp(\"Apple is looking at buying U.K. startup for $1 billion\")\n",
        "\n",
        "for token in doc:\n",
        "    print(token.text, token.lemma_, token.pos_, token.tag_, token.dep_,\n",
        "          token.shape_, token.is_alpha, token.is_stop)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Apple Apple PROPN NNP nsubj Xxxxx True False\n",
            "is be AUX VBZ aux xx True True\n",
            "looking look VERB VBG ROOT xxxx True False\n",
            "at at ADP IN prep xx True True\n",
            "buying buy VERB VBG pcomp xxxx True False\n",
            "U.K. U.K. PROPN NNP compound X.X. False False\n",
            "startup startup NOUN NN dobj xxxx True False\n",
            "for for ADP IN prep xxx True True\n",
            "$ $ SYM $ quantmod $ False False\n",
            "1 1 NUM CD compound d False False\n",
            "billion billion NUM CD pobj xxxx True False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qtbrZZ9fHdsm",
        "outputId": "53312903-21dc-4ba8-a16c-a84cb823eef6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "doc = nlp(\"Autonomous cars shift insurance liability toward manufacturers\")\n",
        "for chunk in doc.noun_chunks:\n",
        "    print(chunk.text, chunk.root.text, chunk.root.dep_,\n",
        "          chunk.root.head.text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Autonomous cars cars nsubj shift\n",
            "insurance liability liability dobj shift\n",
            "manufacturers manufacturers pobj toward\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lVmCeECmHpHN",
        "outputId": "571c0d92-e738-47e0-8691-6b6b7ce58ff4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "doc = nlp(\"Autonomous cars shift insurance liability toward manufacturers\")\n",
        "for token in doc:\n",
        "    print(token.text, token.dep_, token.head.text, token.head.pos_,\n",
        "          [child for child in token.children])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Autonomous amod cars NOUN []\n",
            "cars nsubj shift VERB [Autonomous]\n",
            "shift ROOT shift VERB [cars, liability]\n",
            "insurance compound liability NOUN []\n",
            "liability dobj shift VERB [insurance, toward]\n",
            "toward prep liability NOUN [manufacturers]\n",
            "manufacturers pobj toward ADP []\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4erv5X2hHr3_",
        "outputId": "27cb1d12-895d-4742-8fca-8b6424c486a4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from spacy.symbols import nsubj, VERB\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "doc = nlp(\"Autonomous cars shift insurance liability toward manufacturers\")\n",
        "\n",
        "# Finding a verb with a subject from below â€” good\n",
        "verbs = set()\n",
        "for possible_subject in doc:\n",
        "    if possible_subject.dep == nsubj and possible_subject.head.pos == VERB:\n",
        "        verbs.add(possible_subject.head)\n",
        "print(verbs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{shift}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HMIkwCvsHvpt",
        "outputId": "6c011ba6-f762-4b0e-9eb4-d2d6701f2574",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "verbs = []\n",
        "for possible_verb in doc:\n",
        "    if possible_verb.pos == VERB:\n",
        "        for possible_subject in possible_verb.children:\n",
        "            if possible_subject.dep == nsubj:\n",
        "                verbs.append(possible_verb)\n",
        "                break\n",
        "print(verbs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[shift]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fCeLDQVuHzBu",
        "outputId": "b39079ae-bc35-4046-d3e7-6d2de453a8c2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "doc = nlp(\"bright red apples on the tree\")\n",
        "print([token.text for token in doc[2].lefts])  # ['bright', 'red']\n",
        "print([token.text for token in doc[2].rights])  # ['on']\n",
        "print(doc[2].n_lefts)  # 2\n",
        "print(doc[2].n_rights)  # 1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['bright', 'red']\n",
            "['on']\n",
            "2\n",
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wag-CmGJH3oA",
        "outputId": "5bf40469-c76a-4521-c5b9-bfcfdcff355f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "doc = nlp(\"Credit and mortgage account holders must submit their requests\")\n",
        "root = [token for token in doc if token.head == token][0]\n",
        "subject = list(root.lefts)[0]\n",
        "for descendant in subject.subtree:\n",
        "    assert subject is descendant or subject.is_ancestor(descendant)\n",
        "    print(descendant.text, descendant.dep_, descendant.n_lefts,\n",
        "          descendant.n_rights,\n",
        "          [ancestor.text for ancestor in descendant.ancestors])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Credit nmod 0 2 ['account', 'holders', 'submit']\n",
            "and cc 0 0 ['Credit', 'account', 'holders', 'submit']\n",
            "mortgage conj 0 0 ['Credit', 'account', 'holders', 'submit']\n",
            "account compound 1 0 ['holders', 'submit']\n",
            "holders nsubj 1 0 ['submit']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pihkeXCSH77d",
        "outputId": "b042c770-44d2-463e-c7e1-1f8bc19324bc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "doc = nlp(\"Credit and mortgage account holders must submit their requests\")\n",
        "span = doc[doc[4].left_edge.i : doc[4].right_edge.i+1]\n",
        "with doc.retokenize() as retokenizer:\n",
        "    retokenizer.merge(span)\n",
        "for token in doc:\n",
        "    print(token.text, token.pos_, token.dep_, token.head.text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Credit and mortgage account holders NOUN nsubj submit\n",
            "must VERB aux submit\n",
            "submit VERB ROOT submit\n",
            "their DET poss requests\n",
            "requests NOUN dobj submit\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60vbvOlbIHj8",
        "outputId": "5af9ba14-ce6f-4f31-bb0c-c74c5576a17e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154
        }
      },
      "source": [
        "from spacy import displacy\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "doc = nlp(\"Autonomous cars shift insurance liability toward manufacturers\")\n",
        "# Since this is an interactive Jupyter environment, we can use displacy.render here\n",
        "displacy.render(doc, style='dep')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"057bbfae7b4946c182acfa889f006ad9-0\" class=\"displacy\" width=\"1275\" height=\"312.0\" direction=\"ltr\" style=\"max-width: none; height: 312.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\\n<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\\n    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Autonomous</tspan>\\n    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">ADJ</tspan>\\n</text>\\n\\n<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\\n    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">cars</tspan>\\n    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">NOUN</tspan>\\n</text>\\n\\n<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\\n    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">shift</tspan>\\n    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">VERB</tspan>\\n</text>\\n\\n<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\\n    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">insurance</tspan>\\n    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">NOUN</tspan>\\n</text>\\n\\n<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\\n    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">liability</tspan>\\n    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">NOUN</tspan>\\n</text>\\n\\n<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\\n    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">toward</tspan>\\n    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">ADP</tspan>\\n</text>\\n\\n<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\\n    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">manufacturers</tspan>\\n    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">NOUN</tspan>\\n</text>\\n\\n<g class=\"displacy-arrow\">\\n    <path class=\"displacy-arc\" id=\"arrow-057bbfae7b4946c182acfa889f006ad9-0-0\" stroke-width=\"2px\" d=\"M70,177.0 C70,89.5 220.0,89.5 220.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\\n    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\\n        <textPath xlink:href=\"#arrow-057bbfae7b4946c182acfa889f006ad9-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\\n    </text>\\n    <path class=\"displacy-arrowhead\" d=\"M70,179.0 L62,167.0 78,167.0\" fill=\"currentColor\"/>\\n</g>\\n\\n<g class=\"displacy-arrow\">\\n    <path class=\"displacy-arc\" id=\"arrow-057bbfae7b4946c182acfa889f006ad9-0-1\" stroke-width=\"2px\" d=\"M245,177.0 C245,89.5 395.0,89.5 395.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\\n    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\\n        <textPath xlink:href=\"#arrow-057bbfae7b4946c182acfa889f006ad9-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\\n    </text>\\n    <path class=\"displacy-arrowhead\" d=\"M245,179.0 L237,167.0 253,167.0\" fill=\"currentColor\"/>\\n</g>\\n\\n<g class=\"displacy-arrow\">\\n    <path class=\"displacy-arc\" id=\"arrow-057bbfae7b4946c182acfa889f006ad9-0-2\" stroke-width=\"2px\" d=\"M595,177.0 C595,89.5 745.0,89.5 745.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\\n    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\\n        <textPath xlink:href=\"#arrow-057bbfae7b4946c182acfa889f006ad9-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\\n    </text>\\n    <path class=\"displacy-arrowhead\" d=\"M595,179.0 L587,167.0 603,167.0\" fill=\"currentColor\"/>\\n</g>\\n\\n<g class=\"displacy-arrow\">\\n    <path class=\"displacy-arc\" id=\"arrow-057bbfae7b4946c182acfa889f006ad9-0-3\" stroke-width=\"2px\" d=\"M420,177.0 C420,2.0 750.0,2.0 750.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\\n    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\\n        <textPath xlink:href=\"#arrow-057bbfae7b4946c182acfa889f006ad9-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\\n    </text>\\n    <path class=\"displacy-arrowhead\" d=\"M750.0,179.0 L758.0,167.0 742.0,167.0\" fill=\"currentColor\"/>\\n</g>\\n\\n<g class=\"displacy-arrow\">\\n    <path class=\"displacy-arc\" id=\"arrow-057bbfae7b4946c182acfa889f006ad9-0-4\" stroke-width=\"2px\" d=\"M770,177.0 C770,89.5 920.0,89.5 920.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\\n    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\\n        <textPath xlink:href=\"#arrow-057bbfae7b4946c182acfa889f006ad9-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\\n    </text>\\n    <path class=\"displacy-arrowhead\" d=\"M920.0,179.0 L928.0,167.0 912.0,167.0\" fill=\"currentColor\"/>\\n</g>\\n\\n<g class=\"displacy-arrow\">\\n    <path class=\"displacy-arc\" id=\"arrow-057bbfae7b4946c182acfa889f006ad9-0-5\" stroke-width=\"2px\" d=\"M945,177.0 C945,89.5 1095.0,89.5 1095.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\\n    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\\n        <textPath xlink:href=\"#arrow-057bbfae7b4946c182acfa889f006ad9-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\\n    </text>\\n    <path class=\"displacy-arrowhead\" d=\"M1095.0,179.0 L1103.0,167.0 1087.0,167.0\" fill=\"currentColor\"/>\\n</g>\\n</svg>'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "94RLD1gpIKsA",
        "outputId": "0dcb8734-157e-4d40-dd40-9297ff7e44c0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "doc = nlp(\"Apple is looking at buying U.K. startup for $1 billion\")\n",
        "\n",
        "for ent in doc.ents:\n",
        "    print(ent.text, ent.start_char, ent.end_char, ent.label_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Apple 0 5 ORG\n",
            "U.K. 27 31 GPE\n",
            "$1 billion 44 54 MONEY\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PzqKxze4IR3z",
        "outputId": "f4d5c345-c7e4-4f2f-e809-8939e7cca79c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "doc = nlp(\"San Francisco considers banning sidewalk delivery robots\")\n",
        "\n",
        "# document level\n",
        "ents = [(e.text, e.start_char, e.end_char, e.label_) for e in doc.ents]\n",
        "print(ents)\n",
        "\n",
        "# token level\n",
        "ent_san = [doc[0].text, doc[0].ent_iob_, doc[0].ent_type_]\n",
        "ent_francisco = [doc[1].text, doc[1].ent_iob_, doc[1].ent_type_]\n",
        "print(ent_san)  # ['San', 'B', 'GPE']\n",
        "print(ent_francisco)  # ['Francisco', 'I', 'GPE']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('San Francisco', 0, 13, 'GPE')]\n",
            "['San', 'B', 'GPE']\n",
            "['Francisco', 'I', 'GPE']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHPuihgpIVhG",
        "outputId": "afce29d0-bd8c-4436-baf5-d70d9a036a2a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from spacy.tokens import Span\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "doc = nlp(\"fb is hiring a new vice president of global policy\")\n",
        "ents = [(e.text, e.start_char, e.end_char, e.label_) for e in doc.ents]\n",
        "print('Before', ents)\n",
        "# the model didn't recognise \"fb\" as an entity :(\n",
        "\n",
        "fb_ent = Span(doc, 0, 1, label=\"ORG\") # create a Span for the new entity\n",
        "doc.ents = list(doc.ents) + [fb_ent]\n",
        "\n",
        "ents = [(e.text, e.start_char, e.end_char, e.label_) for e in doc.ents]\n",
        "print('After', ents)\n",
        "# [('fb', 0, 2, 'ORG')] ðŸŽ‰"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Before []\n",
            "After [('fb', 0, 2, 'ORG')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_zwjtJvIc4R",
        "outputId": "38e6cd86-d2da-4157-e895-e79e7821e1c6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import numpy\n",
        "import spacy\n",
        "from spacy.attrs import ENT_IOB, ENT_TYPE\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "doc = nlp.make_doc(\"London is a big city in the United Kingdom.\")\n",
        "print(\"Before\", doc.ents)  # []\n",
        "\n",
        "header = [ENT_IOB, ENT_TYPE]\n",
        "attr_array = numpy.zeros((len(doc), len(header)))\n",
        "attr_array[0, 0] = 3  # B\n",
        "attr_array[0, 1] = doc.vocab.strings[\"GPE\"]\n",
        "doc.from_array(header, attr_array)\n",
        "print(\"After\", doc.ents)  # [London]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Before ()\n",
            "After (London,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W028] Doc.from_array was called with a vector of type 'float64', but is expecting one of type 'uint64' instead. This may result in problems with the vocab further on in the pipeline.\n",
            "  \"__main__\", mod_spec)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6tp-PurIhX6",
        "outputId": "efc818c3-6f0e-4285-9f2c-fcc939628a20",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from spacy import displacy\n",
        "\n",
        "text = \"When Sebastian Thrun started working on self-driving cars at Google in 2007, few people outside of the company took him seriously.\"\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "doc = nlp(text)\n",
        "displacy.serve(doc, style=\"ent\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Using the 'ent' visualizer\n",
            "Serving on http://0.0.0.0:5000 ...\n",
            "\n",
            "Shutting down server on port 5000.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGpKqZPRIkDg",
        "outputId": "a4c548db-a0e6-46fb-b7b5-0e8252423b29",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from spacy.symbols import ORTH\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "doc = nlp(\"gimme that\")  # phrase to tokenize\n",
        "print([w.text for w in doc])  # ['gimme', 'that']\n",
        "\n",
        "# Add special case rule\n",
        "special_case = [{ORTH: \"gim\"}, {ORTH: \"me\"}]\n",
        "nlp.tokenizer.add_special_case(\"gimme\", special_case)\n",
        "\n",
        "# Check new tokenization\n",
        "print([w.text for w in nlp(\"gimme that\")])  # ['gim', 'me', 'that']\n",
        "\n",
        "assert \"gimme\" not in [w.text for w in nlp(\"gimme!\")]\n",
        "assert \"gimme\" not in [w.text for w in nlp('(\"...gimme...?\")')]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['gimme', 'that']\n",
            "['gim', 'me', 'that']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4wnG2xhImzf"
      },
      "source": [
        "nlp.tokenizer.add_special_case(\"...gimme...?\", [{\"ORTH\": \"...gimme...?\"}])\n",
        "assert len(nlp(\"...gimme...?\")) == 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GcavEr4IIpvW",
        "outputId": "d355f937-94e1-4838-d6c8-1c6edbeb0328",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import re\n",
        "import spacy\n",
        "from spacy.tokenizer import Tokenizer\n",
        "\n",
        "special_cases = {\":)\": [{\"ORTH\": \":)\"}]}\n",
        "prefix_re = re.compile(r'''^[[(\"']''')\n",
        "suffix_re = re.compile(r'''[])\"']$''')\n",
        "infix_re = re.compile(r'''[-~]''')\n",
        "simple_url_re = re.compile(r'''^https?://''')\n",
        "\n",
        "def custom_tokenizer(nlp):\n",
        "    return Tokenizer(nlp.vocab, rules=special_cases,\n",
        "                     prefix_search=prefix_re.search,\n",
        "                     suffix_search=suffix_re.search,\n",
        "                     infix_finditer=infix_re.finditer,\n",
        "                     token_match=simple_url_re.match)\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "nlp.tokenizer = custom_tokenizer(nlp)\n",
        "doc = nlp(\"hello-world. :)\")\n",
        "print([t.text for t in doc]) # ['hello', '-', 'world.', ':)']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['hello', '-', 'world.', ':)']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNRiz-VsIz1b",
        "outputId": "4e5cd81d-a873-49b3-d49b-898fc24d278c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from spacy.lang.char_classes import ALPHA, ALPHA_LOWER, ALPHA_UPPER\n",
        "from spacy.lang.char_classes import CONCAT_QUOTES, LIST_ELLIPSES, LIST_ICONS\n",
        "from spacy.util import compile_infix_regex\n",
        "\n",
        "# default tokenizer\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "doc = nlp(\"mother-in-law\")\n",
        "print([t.text for t in doc]) # ['mother', '-', 'in', '-', 'law']\n",
        "\n",
        "# modify tokenizer infix patterns\n",
        "infixes = (\n",
        "        LIST_ELLIPSES\n",
        "        + LIST_ICONS\n",
        "        + [\n",
        "            r\"(?<=[0-9])[+\\-\\*^](?=[0-9-])\",\n",
        "            r\"(?<=[{al}{q}])\\.(?=[{au}{q}])\".format(\n",
        "                al=ALPHA_LOWER, au=ALPHA_UPPER, q=CONCAT_QUOTES\n",
        "            ),\n",
        "            r\"(?<=[{a}]),(?=[{a}])\".format(a=ALPHA),\n",
        "            # EDIT: commented out regex that splits on hyphens between letters:\n",
        "            #r\"(?<=[{a}])(?:{h})(?=[{a}])\".format(a=ALPHA, h=HYPHENS),\n",
        "            r\"(?<=[{a}0-9])[:<>=/](?=[{a}])\".format(a=ALPHA),\n",
        "        ]\n",
        ")\n",
        "\n",
        "infix_re = compile_infix_regex(infixes)\n",
        "nlp.tokenizer.infix_finditer = infix_re.finditer\n",
        "doc = nlp(\"mother-in-law\")\n",
        "print([t.text for t in doc]) # ['mother-in-law']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['mother', '-', 'in', '-', 'law']\n",
            "['mother-in-law']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQHJc-85I2tO",
        "outputId": "67fb8f4a-199a-450f-9f1b-ab2617ae9883",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from spacy.tokens import Doc\n",
        "\n",
        "class WhitespaceTokenizer(object):\n",
        "    def __init__(self, vocab):\n",
        "        self.vocab = vocab\n",
        "\n",
        "    def __call__(self, text):\n",
        "        words = text.split(' ')\n",
        "        # All tokens 'own' a subsequent space character in this tokenizer\n",
        "        spaces = [True] * len(words)\n",
        "        return Doc(self.vocab, words=words, spaces=spaces)\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "nlp.tokenizer = WhitespaceTokenizer(nlp.vocab)\n",
        "doc = nlp(\"What's happened to me? he thought. It wasn't a dream.\")\n",
        "print([t.text for t in doc])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[\"What's\", 'happened', 'to', 'me?', 'he', 'thought.', 'It', \"wasn't\", 'a', 'dream.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uwDUOME2I_v2",
        "outputId": "91fc6984-23fe-45b0-f3fc-bc12816960f6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from spacy.tokens import Doc\n",
        "from spacy.lang.en import English\n",
        "\n",
        "nlp = English()\n",
        "doc = Doc(nlp.vocab, words=[\"Hello\", \",\", \"world\", \"!\"],\n",
        "          spaces=[False, True, False, False])\n",
        "print([(t.text, t.text_with_ws, t.whitespace_) for t in doc])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('Hello', 'Hello', ''), (',', ', ', ' '), ('world', 'world', ''), ('!', '!', '')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WyEoAI6JJEF-",
        "outputId": "4846784e-765f-4f08-a58b-301f2d75fc26",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from spacy.tokens import Doc\n",
        "from spacy.lang.en import English\n",
        "\n",
        "nlp = English()\n",
        "bad_spaces = Doc(nlp.vocab, words=[\"Hello\", \",\", \"world\", \"!\"])\n",
        "good_spaces = Doc(nlp.vocab, words=[\"Hello\", \",\", \"world\", \"!\"],\n",
        "                  spaces=[False, True, False, False])\n",
        "\n",
        "print(bad_spaces.text)   # 'Hello , world !'\n",
        "print(good_spaces.text)  # 'Hello, world!'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hello , world ! \n",
            "Hello, world!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9xsEhm3JHNw",
        "outputId": "169bee40-3e25-4501-eeb6-2079b36d0ba6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from spacy.gold import align\n",
        "\n",
        "other_tokens = [\"i\", \"listened\", \"to\", \"obama\", \"'\", \"s\", \"podcasts\", \".\"]\n",
        "spacy_tokens = [\"i\", \"listened\", \"to\", \"obama\", \"'s\", \"podcasts\", \".\"]\n",
        "cost, a2b, b2a, a2b_multi, b2a_multi = align(other_tokens, spacy_tokens)\n",
        "print(\"Misaligned tokens:\", cost)  # 2\n",
        "print(\"One-to-one mappings a -> b\", a2b)  # array([0, 1, 2, 3, -1, -1, 5, 6])\n",
        "print(\"One-to-one mappings b -> a\", b2a)  # array([0, 1, 2, 3, 5, 6, 7])\n",
        "print(\"Many-to-one mappings a -> b\", a2b_multi)  # {4: 4, 5: 4}\n",
        "print(\"Many-to-one mappings b-> a\", b2a_multi)  # {}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Misaligned tokens: 2\n",
            "One-to-one mappings a -> b [ 0  1  2  3 -1 -1  5  6]\n",
            "One-to-one mappings b -> a [0 1 2 3 5 6 7]\n",
            "Many-to-one mappings a -> b {4: 4, 5: 4}\n",
            "Many-to-one mappings b-> a {}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vz0RnYY2JKWE",
        "outputId": "8a1743d9-2b78-440f-f6db-4c2cba98ff55",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "doc = nlp(\"I live in New York\")\n",
        "print(\"Before:\", [token.text for token in doc])\n",
        "\n",
        "with doc.retokenize() as retokenizer:\n",
        "    retokenizer.merge(doc[3:5], attrs={\"LEMMA\": \"new york\"})\n",
        "print(\"After:\", [token.text for token in doc])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Before: ['I', 'live', 'in', 'New', 'York']\n",
            "After: ['I', 'live', 'in', 'New York']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4uu7FkyhJM-g",
        "outputId": "4c03eedf-e8bc-48e5-a3e0-905aa8d0ee13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188
        }
      },
      "source": [
        "from spacy import displacy\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "doc = nlp(\"I live in NewYork\")\n",
        "print(\"Before:\", [token.text for token in doc])\n",
        "displacy.render(doc)  # displacy.serve if you're not in a Jupyter environment\n",
        "\n",
        "with doc.retokenize() as retokenizer:\n",
        "    heads = [(doc[3], 1), doc[2]]\n",
        "    attrs = {\"POS\": [\"PROPN\", \"PROPN\"], \"DEP\": [\"pobj\", \"compound\"]}\n",
        "    retokenizer.split(doc[3], [\"New\", \"York\"], heads=heads, attrs=attrs)\n",
        "print(\"After:\", [token.text for token in doc])\n",
        "displacy.render(doc)  # displacy.serve if you're not in a Jupyter environment"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Before: ['I', 'live', 'in', 'NewYork']\n",
            "After: ['I', 'live', 'in', 'New', 'York']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"868ecbcaf1e941cebbef5015b2ea7351-0\" class=\"displacy\" width=\"925\" height=\"312.0\" direction=\"ltr\" style=\"max-width: none; height: 312.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\\n<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\\n    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">I</tspan>\\n    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PRON</tspan>\\n</text>\\n\\n<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\\n    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">live</tspan>\\n    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">VERB</tspan>\\n</text>\\n\\n<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\\n    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">in</tspan>\\n    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">ADP</tspan>\\n</text>\\n\\n<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\\n    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">New</tspan>\\n    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">PROPN</tspan>\\n</text>\\n\\n<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\\n    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">York</tspan>\\n    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">PROPN</tspan>\\n</text>\\n\\n<g class=\"displacy-arrow\">\\n    <path class=\"displacy-arc\" id=\"arrow-868ecbcaf1e941cebbef5015b2ea7351-0-0\" stroke-width=\"2px\" d=\"M70,177.0 C70,89.5 220.0,89.5 220.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\\n    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\\n        <textPath xlink:href=\"#arrow-868ecbcaf1e941cebbef5015b2ea7351-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\\n    </text>\\n    <path class=\"displacy-arrowhead\" d=\"M70,179.0 L62,167.0 78,167.0\" fill=\"currentColor\"/>\\n</g>\\n\\n<g class=\"displacy-arrow\">\\n    <path class=\"displacy-arc\" id=\"arrow-868ecbcaf1e941cebbef5015b2ea7351-0-1\" stroke-width=\"2px\" d=\"M245,177.0 C245,89.5 395.0,89.5 395.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\\n    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\\n        <textPath xlink:href=\"#arrow-868ecbcaf1e941cebbef5015b2ea7351-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\\n    </text>\\n    <path class=\"displacy-arrowhead\" d=\"M395.0,179.0 L403.0,167.0 387.0,167.0\" fill=\"currentColor\"/>\\n</g>\\n\\n<g class=\"displacy-arrow\">\\n    <path class=\"displacy-arc\" id=\"arrow-868ecbcaf1e941cebbef5015b2ea7351-0-2\" stroke-width=\"2px\" d=\"M595,177.0 C595,89.5 745.0,89.5 745.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\\n    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\\n        <textPath xlink:href=\"#arrow-868ecbcaf1e941cebbef5015b2ea7351-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\\n    </text>\\n    <path class=\"displacy-arrowhead\" d=\"M595,179.0 L587,167.0 603,167.0\" fill=\"currentColor\"/>\\n</g>\\n\\n<g class=\"displacy-arrow\">\\n    <path class=\"displacy-arc\" id=\"arrow-868ecbcaf1e941cebbef5015b2ea7351-0-3\" stroke-width=\"2px\" d=\"M420,177.0 C420,2.0 750.0,2.0 750.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\\n    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\\n        <textPath xlink:href=\"#arrow-868ecbcaf1e941cebbef5015b2ea7351-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\\n    </text>\\n    <path class=\"displacy-arrowhead\" d=\"M750.0,179.0 L758.0,167.0 742.0,167.0\" fill=\"currentColor\"/>\\n</g>\\n</svg>'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "agvjyx82JQIz",
        "outputId": "1d42fe17-33ea-4ee6-a8a6-c2a8cf0265c6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from spacy.tokens import Token\n",
        "\n",
        "# Register a custom token attribute, token._.is_musician\n",
        "Token.set_extension(\"is_musician\", default=False)\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "doc = nlp(\"I like David Bowie\")\n",
        "print(\"Before:\", [(token.text, token._.is_musician) for token in doc])\n",
        "\n",
        "with doc.retokenize() as retokenizer:\n",
        "    retokenizer.merge(doc[2:4], attrs={\"_\": {\"is_musician\": True}})\n",
        "print(\"After:\", [(token.text, token._.is_musician) for token in doc])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Before: [('I', False), ('like', False), ('David', False), ('Bowie', False)]\n",
            "After: [('I', False), ('like', False), ('David Bowie', True)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DK5wZQABJSa1",
        "outputId": "ebe9d89a-753d-4c3a-b3b9-79f8b01c59de",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from spacy.lang.en import English\n",
        "\n",
        "nlp = English()  # just the language with no model\n",
        "sentencizer = nlp.create_pipe(\"sentencizer\")\n",
        "nlp.add_pipe(sentencizer)\n",
        "doc = nlp(\"This is a sentence. This is another sentence.\")\n",
        "for sent in doc.sents:\n",
        "    print(sent.text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This is a sentence.\n",
            "This is another sentence.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yas5TLoTJU-a",
        "outputId": "c3e97c33-eb0a-4525-972c-429ba317edf3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "text = \"this is a sentence...hello...and another sentence.\"\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "doc = nlp(text)\n",
        "print(\"Before:\", [sent.text for sent in doc.sents])\n",
        "\n",
        "def set_custom_boundaries(doc):\n",
        "    for token in doc[:-1]:\n",
        "        if token.text == \"...\":\n",
        "            doc[token.i+1].is_sent_start = True\n",
        "    return doc\n",
        "\n",
        "nlp.add_pipe(set_custom_boundaries, before=\"parser\")\n",
        "doc = nlp(text)\n",
        "print(\"After:\", [sent.text for sent in doc.sents])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Before: ['this is a sentence...', 'hello...and another sentence.']\n",
            "After: ['this is a sentence...', 'hello...', 'and another sentence.']\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}