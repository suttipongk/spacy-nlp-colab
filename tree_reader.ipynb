{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "37_tree_reader.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kullawattana/thesis_2020_spacy_colab/blob/master/37_tree_reader.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJf1YwOdy7AH",
        "outputId": "416a1b4c-e44c-46ea-a93d-9252df4f65a3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import spacy \n",
        "from nltk import Tree\n",
        "#import spacy.utils.nltk\n",
        "#from spacy.utils.nltk import Tree\n",
        "#from spacy.utils.nltk.tokenize import word_tokenize\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "#Import txt file\n",
        "#text = \"This is a test. This is another test. the little yellow dog barked at the cat.\"\n",
        "\n",
        "'''\n",
        "f = open(r\"/Users/toppee/Desktop/requirement.txt\") \n",
        "while text:\n",
        "    text = f.readline()\n",
        "f.close()\n",
        "'''\n",
        "\n",
        "#text = open('/Users/toppee/Desktop/requirement.txt','r').read().replace('\\n',' ')\n",
        "text = \"This is a books\"\n",
        "print(text)\n",
        "\n",
        "'''\n",
        "text = open('/Users/toppee/Desktop/requirement.txt', 'r') as file:\n",
        "    text = file.read().replace('\\n', '')\n",
        "    print(text)\n",
        "'''\n",
        "\n",
        "def to_nltk_tree(node):\n",
        "    if node.n_lefts + node.n_rights > 0:\n",
        "        return Tree(node.orth_, [to_nltk_tree(child) for child in node.children])\n",
        "    else:\n",
        "        return node.orth_\n",
        "\n",
        "sentence_tokens = []\n",
        "doc = nlp(text) \n",
        "\n",
        "\n",
        "for sent in doc.sents:\n",
        "    to_nltk_tree(sent.root).pretty_print() \n",
        "\n",
        "for sent in doc.sents:\n",
        "    words = nlp(sent.text)\n",
        "    all = []\n",
        "    for w in words:\n",
        "        all.append(w)\n",
        "        sentence_tokens.append(all)\n",
        "\n",
        "#tag = spacy.utils.nltk.pos_tag(text)\n",
        "#print(tag)\n",
        "#sentence = spacy.utils.nltk.pos_tag(text)\n",
        "#sentence = [(\"the\", \"DT\"), (\"little\", \"JJ\"), (\"yellow\", \"JJ\"), (\"dog\", \"NN\"), (\"barked\",\"VBD\"), (\"at\", \"IN\"), (\"the\", \"DT\"), (\"cat\", \"NN\")]\n",
        "#pattern = \"\"\"NP: {<DT>?<JJ>*<NN>}\n",
        "#VBD: {<VBD>}\n",
        "#IN: {<IN>}\"\"\"\n",
        "#NPChunker = spacy.utils.nltk.RegexpParser(pattern)\n",
        "#result = NPChunker.parse(sentence)\n",
        "#result.draw()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This is a books\n",
            "      is      \n",
            "  ____|____    \n",
            " |       books\n",
            " |         |   \n",
            "This       a  \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}