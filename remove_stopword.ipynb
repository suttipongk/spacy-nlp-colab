{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "50_remove_stopword.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kullawattana/thesis_2020_spacy_colab/blob/master/50_remove_stopword.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9K47ZWvlG2k",
        "outputId": "8e49dc59-5bb7-4a84-ee6d-680c765803bc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#----------------Remove Stopwords---------------\n",
        "from spacy.lang.en import English\n",
        "\n",
        "# Load English tokenizer, tagger, parser, NER and word vectors\n",
        "nlp = English()\n",
        "\n",
        "text = \"\"\"In the context of a claim handling process, \n",
        "it is sometimes necessary to send a questionnaire to the claimant to gather additional information. \n",
        "The claimant is expected to return the questionnaire within five days. \n",
        "If no response is received after five days, a reminder is sent to the claimant. \n",
        "If after another five days there is still no response, another reminder is sent \n",
        "and so on until the completed questionnaire is received.\"\"\"\n",
        "\n",
        "#  \"nlpframework\" Object is used to create documents with linguistic annotations.\n",
        "my_doc = nlp(text)\n",
        "\n",
        "# Create list of word tokens\n",
        "token_list = []\n",
        "for token in my_doc:\n",
        "    token_list.append(token.text)\n",
        "\n",
        "from spacy.lang.en.stop_words import STOP_WORDS\n",
        "\n",
        "# Create list of word tokens after removing stopwords\n",
        "filtered_sentence =[] \n",
        "\n",
        "for word in token_list:\n",
        "    lexeme = nlp.vocab[word]\n",
        "    if lexeme.is_stop == False:\n",
        "        filtered_sentence.append(word) \n",
        "print(token_list)\n",
        "print(filtered_sentence)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['In', 'the', 'context', 'of', 'a', 'claim', 'handling', 'process', ',', '\\n', 'it', 'is', 'sometimes', 'necessary', 'to', 'send', 'a', 'questionnaire', 'to', 'the', 'claimant', 'to', 'gather', 'additional', 'information', '.', '\\n', 'The', 'claimant', 'is', 'expected', 'to', 'return', 'the', 'questionnaire', 'within', 'five', 'days', '.', '\\n', 'If', 'no', 'response', 'is', 'received', 'after', 'five', 'days', ',', 'a', 'reminder', 'is', 'sent', 'to', 'the', 'claimant', '.', '\\n', 'If', 'after', 'another', 'five', 'days', 'there', 'is', 'still', 'no', 'response', ',', 'another', 'reminder', 'is', 'sent', '\\n', 'and', 'so', 'on', 'until', 'the', 'completed', 'questionnaire', 'is', 'received', '.']\n",
            "['context', 'claim', 'handling', 'process', ',', '\\n', 'necessary', 'send', 'questionnaire', 'claimant', 'gather', 'additional', 'information', '.', '\\n', 'claimant', 'expected', 'return', 'questionnaire', 'days', '.', '\\n', 'response', 'received', 'days', ',', 'reminder', 'sent', 'claimant', '.', '\\n', 'days', 'response', ',', 'reminder', 'sent', '\\n', 'completed', 'questionnaire', 'received', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}